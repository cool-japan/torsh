{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Getting Started with ToRSh\n",
        "\n",
        "Welcome to ToRSh (Tensor Operations in Rust with Sharding)! This notebook will guide you through the basics of using ToRSh for tensor operations and machine learning.\n",
        "\n",
        "## What is ToRSh?\n",
        "\n",
        "ToRSh is a production-ready deep learning framework built in pure Rust. It leverages Rust's zero-cost abstractions, memory safety, and the scirs2 ecosystem to provide a PyTorch-compatible API with superior performance.\n",
        "\n",
        "## Key Features\n",
        "\n",
        "- ðŸš€ **High Performance**: Built with Rust for maximum speed and efficiency\n",
        "- ðŸ”’ **Memory Safe**: Rust's ownership system prevents memory leaks and data races\n",
        "- ðŸ§  **PyTorch Compatible**: Familiar API for easy migration from PyTorch\n",
        "- ðŸŽ¯ **Production Ready**: Enterprise-grade reliability and scalability\n",
        "- ðŸ”§ **Comprehensive**: Full ecosystem with autograd, neural networks, and data loading\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Installation\n",
        "\n",
        "To use ToRSh in your Rust project, add it to your `Cargo.toml`:\n",
        "\n",
        "```toml\n",
        "[dependencies]\n",
        "torsh = \"0.1.0-alpha.1\"\n",
        "```\n",
        "\n",
        "For this notebook, we'll assume you have ToRSh installed and can import it:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "// Import ToRSh prelude for convenience\n",
        "use torsh::prelude::*;\n",
        "use std::result::Result as StdResult;\n",
        "\n",
        "println!(\"ToRSh imported successfully!\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Creating Your First Tensor\n",
        "\n",
        "Let's start with the fundamental building block of ToRSh: tensors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "// Create a tensor from data\n",
        "let data = vec![1.0f32, 2.0, 3.0, 4.0, 5.0, 6.0];\n",
        "let tensor = Tensor::from_data(data, vec![2, 3], DeviceType::Cpu)?;\n",
        "\n",
        "println!(\"Created tensor: {:?}\", tensor);\n",
        "println!(\"Shape: {:?}\", tensor.shape());\n",
        "println!(\"Device: {:?}\", tensor.device());\n",
        "println!(\"Number of elements: {}\", tensor.numel());"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Tensor Creation Functions\n",
        "\n",
        "ToRSh provides many convenient functions for creating tensors:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "// Create tensors with different initialization methods\n",
        "\n",
        "// Zeros tensor\n",
        "let zeros_tensor = zeros::<f32>(&[3, 3])?;\n",
        "println!(\"Zeros tensor: {:?}\", zeros_tensor);\n",
        "\n",
        "// Ones tensor\n",
        "let ones_tensor = ones::<f32>(&[2, 4])?;\n",
        "println!(\"Ones tensor: {:?}\", ones_tensor);\n",
        "\n",
        "// Random tensor (normal distribution)\n",
        "let rand_tensor = randn::<f32>(&[2, 2])?;\n",
        "println!(\"Random tensor: {:?}\", rand_tensor);\n",
        "\n",
        "// Identity matrix\n",
        "let eye_tensor = eye::<f32>(3)?;\n",
        "println!(\"Identity matrix: {:?}\", eye_tensor);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Basic Tensor Operations\n",
        "\n",
        "ToRSh supports all the standard tensor operations you'd expect:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "// Create two tensors for operations\n",
        "let a = Tensor::from_data(vec![1.0f32, 2.0, 3.0, 4.0], vec![2, 2], DeviceType::Cpu)?;\n",
        "let b = Tensor::from_data(vec![2.0f32, 3.0, 4.0, 5.0], vec![2, 2], DeviceType::Cpu)?;\n",
        "\n",
        "println!(\"Tensor A: {:?}\", a);\n",
        "println!(\"Tensor B: {:?}\", b);\n",
        "\n",
        "// Element-wise operations\n",
        "let sum = a.add(&b)?;\n",
        "println!(\"A + B = {:?}\", sum);\n",
        "\n",
        "let diff = a.sub(&b)?;\n",
        "println!(\"A - B = {:?}\", diff);\n",
        "\n",
        "let product = a.mul(&b)?;\n",
        "println!(\"A * B (element-wise) = {:?}\", product);\n",
        "\n",
        "// Matrix multiplication\n",
        "let matmul_result = a.matmul(&b)?;\n",
        "println!(\"A @ B (matrix multiplication) = {:?}\", matmul_result);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Broadcasting\n",
        "\n",
        "ToRSh supports NumPy-style broadcasting for operations between tensors of different shapes:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "// Create tensors with different shapes\n",
        "let large = randn::<f32>(&[3, 4])?;\n",
        "let small = randn::<f32>(&[1, 4])?;  // Will broadcast across the first dimension\n",
        "let scalar = Tensor::from_data(vec![2.0f32], vec![], DeviceType::Cpu)?;\n",
        "\n",
        "println!(\"Large tensor shape: {:?}\", large.shape());\n",
        "println!(\"Small tensor shape: {:?}\", small.shape());\n",
        "println!(\"Scalar shape: {:?}\", scalar.shape());\n",
        "\n",
        "// Broadcasting addition\n",
        "let broadcast_result = large.add(&small)?;\n",
        "println!(\"Broadcast result shape: {:?}\", broadcast_result.shape());\n",
        "\n",
        "// Scalar operations\n",
        "let scalar_result = large.mul(&scalar)?;\n",
        "println!(\"Scalar multiplication result shape: {:?}\", scalar_result.shape());"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Tensor Reshaping\n",
        "\n",
        "Manipulate tensor shapes without changing the data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "let original = randn::<f32>(&[2, 6])?;\n",
        "println!(\"Original shape: {:?}\", original.shape());\n",
        "\n",
        "// Reshape to different dimensions\n",
        "let reshaped = original.reshape(&[3, 4])?;\n",
        "println!(\"Reshaped to [3, 4]: {:?}\", reshaped.shape());\n",
        "\n",
        "// Flatten to 1D\n",
        "let flattened = original.reshape(&[12])?;\n",
        "println!(\"Flattened to [12]: {:?}\", flattened.shape());\n",
        "\n",
        "// Add and remove dimensions\n",
        "let expanded = original.unsqueeze(0)?;  // Add dimension at index 0\n",
        "println!(\"Unsqueezed at dim 0: {:?}\", expanded.shape());\n",
        "\n",
        "let squeezed = expanded.squeeze(0)?;    // Remove dimension at index 0\n",
        "println!(\"Squeezed at dim 0: {:?}\", squeezed.shape());"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Mathematical Functions\n",
        "\n",
        "ToRSh provides a comprehensive set of mathematical functions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "let data = Tensor::from_data(vec![0.0f32, 1.0, 2.0, 3.0], vec![2, 2], DeviceType::Cpu)?;\n",
        "println!(\"Original data: {:?}\", data);\n",
        "\n",
        "// Exponential and logarithmic functions\n",
        "let exp_result = data.exp()?;\n",
        "println!(\"Exponential: {:?}\", exp_result);\n",
        "\n",
        "let positive_data = data.abs()?.add_scalar(1.0)?;  // Ensure positive for log\n",
        "let log_result = positive_data.log()?;\n",
        "println!(\"Natural logarithm: {:?}\", log_result);\n",
        "\n",
        "// Trigonometric functions\n",
        "let sin_result = data.sin()?;\n",
        "println!(\"Sine: {:?}\", sin_result);\n",
        "\n",
        "let cos_result = data.cos()?;\n",
        "println!(\"Cosine: {:?}\", cos_result);\n",
        "\n",
        "// Activation functions\n",
        "let relu_result = data.relu()?;\n",
        "println!(\"ReLU: {:?}\", relu_result);\n",
        "\n",
        "let sigmoid_result = data.sigmoid()?;\n",
        "println!(\"Sigmoid: {:?}\", sigmoid_result);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Reduction Operations\n",
        "\n",
        "Reduce tensors along specific dimensions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "let tensor = randn::<f32>(&[3, 4])?;\n",
        "println!(\"Original tensor shape: {:?}\", tensor.shape());\n",
        "\n",
        "// Reduce all elements\n",
        "let sum_all = tensor.sum()?;\n",
        "println!(\"Sum of all elements: {:?}\", sum_all);\n",
        "\n",
        "let mean_all = tensor.mean()?;\n",
        "println!(\"Mean of all elements: {:?}\", mean_all);\n",
        "\n",
        "let max_all = tensor.max(None, false)?;\n",
        "println!(\"Maximum element: {:?}\", max_all);\n",
        "\n",
        "let min_all = tensor.min(None, false)?;\n",
        "println!(\"Minimum element: {:?}\", min_all);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Next Steps\n",
        "\n",
        "Congratulations! You've learned the basics of ToRSh tensor operations. Here's what you can explore next:\n",
        "\n",
        "### More Notebooks\n",
        "- **02_autograd_and_gradients.ipynb**: Learn about automatic differentiation\n",
        "- **03_neural_networks.ipynb**: Build your first neural network\n",
        "- **04_training_loops.ipynb**: Train models with optimization\n",
        "- **05_advanced_features.ipynb**: Explore advanced ToRSh features\n",
        "\n",
        "### Documentation\n",
        "- Check out the comprehensive guides in the `docs/` directory\n",
        "- Browse the API reference for detailed function documentation\n",
        "- Look at the examples in `examples/` for real-world use cases\n",
        "\n",
        "### Community\n",
        "- Join the ToRSh community discussions\n",
        "- Contribute to the project on GitHub\n",
        "- Share your ToRSh projects and experiences\n",
        "\n",
        "Happy coding with ToRSh! ðŸš€"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Rust",
      "language": "rust",
      "name": "rust"
    },
    "language_info": {
      "codemirror_mode": "rust",
      "file_extension": ".rs",
      "mimetype": "text/rust",
      "name": "Rust",
      "pygment_lexer": "rust",
      "version": ""
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}