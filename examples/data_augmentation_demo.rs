//! Comprehensive Data Augmentation Framework Demo
//!
//! This example demonstrates the complete data augmentation capabilities in ToRSh including:
//! - Basic geometric transforms (resize, crop, flip)
//! - Color augmentations (color jitter, brightness, contrast)
//! - Advanced transforms (random resized crop, random erasing)
//! - Normalization and preprocessing pipelines
//! - Integration with data loading and training workflows

use image::{DynamicImage, ImageBuffer, Rgb};
use std::error::Error;
use torsh_tensor::creation::*;
use torsh_tensor::Tensor;
use torsh_vision::transforms::*;

/// Configuration for data augmentation demonstration
#[derive(Debug, Clone)]
pub struct AugmentationConfig {
    pub image_size: (usize, usize),
    pub crop_size: (usize, usize),
    pub batch_size: usize,
    pub num_examples: usize,
}

impl Default for AugmentationConfig {
    fn default() -> Self {
        Self {
            image_size: (256, 256),
            crop_size: (224, 224),
            batch_size: 4,
            num_examples: 8,
        }
    }
}

fn main() -> Result<(), Box<dyn Error>> {
    println!("ðŸ–¼ï¸  Comprehensive Data Augmentation Framework Demo");
    println!("==================================================\n");

    let config = AugmentationConfig::default();

    // Demonstrate different augmentation pipelines
    demonstrate_basic_transforms(&config)?;
    demonstrate_training_augmentations(&config)?;
    demonstrate_test_augmentations(&config)?;
    demonstrate_advanced_augmentations(&config)?;
    demonstrate_custom_pipelines(&config)?;
    demonstrate_performance_considerations(&config)?;

    println!("\nâœ… Data augmentation framework demonstration completed!");
    Ok(())
}

/// Demonstrate basic geometric transforms
fn demonstrate_basic_transforms(config: &AugmentationConfig) -> Result<(), Box<dyn Error>> {
    println!("ðŸ”„ Basic Geometric Transforms Demo");
    println!("==================================\n");

    // Create a sample tensor (C, H, W format)
    let input_tensor = randn(&[3, config.image_size.1, config.image_size.0]);
    println!("ðŸ“Š Input tensor shape: {:?}", input_tensor.shape());

    // Test basic transforms
    let transforms = vec![
        (
            "Resize",
            Box::new(Resize::new(config.crop_size)) as Box<dyn Transform>,
        ),
        ("Center Crop", Box::new(CenterCrop::new(config.crop_size))),
        (
            "Random Horizontal Flip",
            Box::new(RandomHorizontalFlip::new(0.5)),
        ),
        (
            "Random Vertical Flip",
            Box::new(RandomVerticalFlip::new(0.3)),
        ),
        ("Random Crop", Box::new(RandomCrop::new(config.crop_size))),
    ];

    for (name, transform) in transforms {
        match transform.forward(&input_tensor) {
            Ok(output) => {
                println!(
                    "   âœ“ {}: {:?} -> {:?}",
                    name,
                    input_tensor.shape(),
                    output.shape()
                );
            }
            Err(e) => {
                println!("   âœ— {}: Error - {}", name, e);
            }
        }
    }

    println!("\nðŸ’¡ Basic Transform Guidelines:");
    println!("   â€¢ Resize: Use bilinear interpolation for best quality");
    println!("   â€¢ Center Crop: Deterministic cropping for test/validation");
    println!("   â€¢ Random Crop: Data augmentation for training");
    println!("   â€¢ Horizontal Flip: Common for natural images (probability 0.5)");
    println!("   â€¢ Vertical Flip: Use carefully, may not be appropriate for all datasets\n");

    Ok(())
}

/// Demonstrate training augmentation pipeline
fn demonstrate_training_augmentations(config: &AugmentationConfig) -> Result<(), Box<dyn Error>> {
    println!("ðŸ‹ï¸  Training Augmentation Pipeline Demo");
    println!("======================================\n");

    let input_tensor = randn(&[3, config.image_size.1, config.image_size.0]);

    // Training augmentation pipeline (more aggressive)
    let training_pipeline = Compose::new(vec![
        Box::new(
            RandomResizedCrop::new(config.crop_size)
                .with_scale((0.08, 1.0))
                .with_ratio((3.0 / 4.0, 4.0 / 3.0)),
        ),
        Box::new(RandomHorizontalFlip::new(0.5)),
        Box::new(
            ColorJitter::new()
                .brightness(0.4)
                .contrast(0.4)
                .saturation(0.4)
                .hue(0.1),
        ),
        Box::new(
            RandomErasing::new(0.25)
                .with_scale((0.02, 0.33))
                .with_ratio((0.3, 3.3)),
        ),
        Box::new(Normalize::new(
            vec![0.485, 0.456, 0.406], // ImageNet mean
            vec![0.229, 0.224, 0.225], // ImageNet std
        )),
    ]);

    println!("ðŸ“ˆ Training Pipeline Components:");
    println!("   1. Random Resized Crop (scale: 0.08-1.0, ratio: 0.75-1.33)");
    println!("   2. Random Horizontal Flip (p=0.5)");
    println!("   3. Color Jitter (brightnessÂ±0.4, contrastÂ±0.4, saturationÂ±0.4, hueÂ±0.1)");
    println!("   4. Random Erasing (p=0.25, scale: 0.02-0.33)");
    println!("   5. ImageNet Normalization");

    // Apply pipeline multiple times to show variation
    println!("\nðŸŽ² Pipeline Variation Examples:");
    for i in 1..=3 {
        match training_pipeline.forward(&input_tensor) {
            Ok(output) => {
                println!(
                    "   Example {}: {:?} -> {:?}",
                    i,
                    input_tensor.shape(),
                    output.shape()
                );
            }
            Err(e) => {
                println!("   Example {}: Error - {}", i, e);
            }
        }
    }

    println!("\nðŸ’¡ Training Augmentation Best Practices:");
    println!("   â€¢ Use random resized crop for scale and aspect ratio invariance");
    println!("   â€¢ Apply horizontal flip for natural images");
    println!("   â€¢ Use moderate color jitter to improve robustness");
    println!("   â€¢ Random erasing helps with occlusion robustness");
    println!("   â€¢ Always normalize as the final step\n");

    Ok(())
}

/// Demonstrate test/validation augmentation pipeline
fn demonstrate_test_augmentations(config: &AugmentationConfig) -> Result<(), Box<dyn Error>> {
    println!("ðŸ§ª Test/Validation Augmentation Pipeline Demo");
    println!("==============================================\n");

    let input_tensor = randn(&[3, config.image_size.1, config.image_size.0]);

    // Test augmentation pipeline (deterministic)
    let test_pipeline = Compose::new(vec![
        Box::new(Resize::new((256, 256))),
        Box::new(CenterCrop::new(config.crop_size)),
        Box::new(Normalize::new(
            vec![0.485, 0.456, 0.406], // ImageNet mean
            vec![0.229, 0.224, 0.225], // ImageNet std
        )),
    ]);

    println!("ðŸ”¬ Test Pipeline Components:");
    println!("   1. Resize to 256x256 (preserve aspect ratio)");
    println!("   2. Center Crop to 224x224");
    println!("   3. ImageNet Normalization");

    match test_pipeline.forward(&input_tensor) {
        Ok(output) => {
            println!(
                "\nâœ“ Test pipeline result: {:?} -> {:?}",
                input_tensor.shape(),
                output.shape()
            );
        }
        Err(e) => {
            println!("\nâœ— Test pipeline error: {}", e);
        }
    }

    // Alternative: Ten Crop for test-time augmentation
    println!("\nðŸ“Š Test-Time Augmentation (TTA) Options:");
    println!("   â€¢ Single Center Crop (fastest, implemented above)");
    println!("   â€¢ Ten Crop: 4 corners + center + horizontal flips");
    println!("   â€¢ Multi-Scale Testing: Test at different scales");
    println!("   â€¢ Ensemble Methods: Average predictions from multiple augmentations");

    println!("\nðŸ’¡ Test Augmentation Guidelines:");
    println!("   â€¢ Keep deterministic for reproducible results");
    println!("   â€¢ Use center crop for fair evaluation");
    println!("   â€¢ Consider TTA for improved accuracy (at cost of speed)");
    println!("   â€¢ Match normalization used during training\n");

    Ok(())
}

/// Demonstrate advanced augmentation techniques
fn demonstrate_advanced_augmentations(_config: &AugmentationConfig) -> Result<(), Box<dyn Error>> {
    println!("ðŸš€ Advanced Augmentation Techniques Demo");
    println!("========================================\n");

    let input_tensor = randn(&[3, 224, 224]);

    println!("ðŸŽ¯ Advanced Techniques Available:");

    // Random Erasing variations
    println!("\n1. Random Erasing Variants:");
    let erasing_configs = vec![
        (
            "Conservative",
            RandomErasing::new(0.1).with_scale((0.02, 0.15)),
        ),
        (
            "Standard",
            RandomErasing::new(0.25).with_scale((0.02, 0.33)),
        ),
        (
            "Aggressive",
            RandomErasing::new(0.5).with_scale((0.05, 0.5)),
        ),
    ];

    for (name, transform) in erasing_configs {
        match transform.forward(&input_tensor) {
            Ok(_) => println!("   âœ“ {} Erasing: Successfully applied", name),
            Err(e) => println!("   âœ— {} Erasing: Error - {}", name, e),
        }
    }

    // Color Jitter variations
    println!("\n2. Color Jitter Variants:");
    let color_configs = vec![
        ("Subtle", ColorJitter::new().brightness(0.1).contrast(0.1)),
        (
            "Moderate",
            ColorJitter::new()
                .brightness(0.2)
                .contrast(0.2)
                .saturation(0.2),
        ),
        (
            "Strong",
            ColorJitter::new()
                .brightness(0.4)
                .contrast(0.4)
                .saturation(0.4)
                .hue(0.1),
        ),
    ];

    for (name, transform) in color_configs {
        match transform.forward(&input_tensor) {
            Ok(_) => println!("   âœ“ {} Color Jitter: Successfully applied", name),
            Err(e) => println!("   âœ— {} Color Jitter: Error - {}", name, e),
        }
    }

    // Geometric variations
    println!("\n3. Geometric Transform Variants:");
    let geometric_configs = vec![
        (
            "Mild Crop",
            RandomResizedCrop::new((224, 224)).with_scale((0.8, 1.0)),
        ),
        (
            "Standard Crop",
            RandomResizedCrop::new((224, 224)).with_scale((0.08, 1.0)),
        ),
        (
            "Extreme Crop",
            RandomResizedCrop::new((224, 224)).with_scale((0.05, 1.0)),
        ),
    ];

    for (name, transform) in geometric_configs {
        match transform.forward(&input_tensor) {
            Ok(_) => println!("   âœ“ {}: Successfully applied", name),
            Err(e) => println!("   âœ— {}: Error - {}", name, e),
        }
    }

    println!("\nðŸ’¡ Advanced Augmentation Guidelines:");
    println!("   â€¢ Random Erasing: Start conservative, increase for robustness");
    println!("   â€¢ Color Jitter: Adjust based on dataset characteristics");
    println!("   â€¢ Geometric Transforms: Balance diversity with semantic preservation");
    println!("   â€¢ Always validate augmentations don't hurt performance");
    println!("   â€¢ Consider domain-specific augmentations for specialized tasks\n");

    Ok(())
}

/// Demonstrate custom augmentation pipelines
fn demonstrate_custom_pipelines(_config: &AugmentationConfig) -> Result<(), Box<dyn Error>> {
    println!("âš™ï¸  Custom Augmentation Pipelines Demo");
    println!("======================================\n");

    let input_tensor = randn(&[3, 224, 224]);

    println!("ðŸ“‹ Task-Specific Pipeline Examples:\n");

    // 1. Classification Pipeline
    println!("1. ðŸ·ï¸  Image Classification Pipeline:");
    let classification_pipeline = Compose::new(vec![
        Box::new(RandomResizedCrop::new((224, 224))),
        Box::new(RandomHorizontalFlip::new(0.5)),
        Box::new(
            ColorJitter::new()
                .brightness(0.4)
                .contrast(0.4)
                .saturation(0.4),
        ),
        Box::new(Normalize::new(
            vec![0.485, 0.456, 0.406],
            vec![0.229, 0.224, 0.225],
        )),
    ]);

    match classification_pipeline.forward(&input_tensor) {
        Ok(_) => println!("   âœ“ Classification pipeline: Successfully applied"),
        Err(e) => println!("   âœ— Classification pipeline: Error - {}", e),
    }

    // 2. Object Detection Pipeline (more conservative)
    println!("\n2. ðŸ“¦ Object Detection Pipeline:");
    let detection_pipeline = Compose::new(vec![
        Box::new(Resize::new((512, 512))),
        Box::new(RandomHorizontalFlip::new(0.5)),
        Box::new(ColorJitter::new().brightness(0.2).contrast(0.2)),
        Box::new(Normalize::new(
            vec![0.485, 0.456, 0.406],
            vec![0.229, 0.224, 0.225],
        )),
    ]);

    match detection_pipeline.forward(&input_tensor) {
        Ok(_) => println!("   âœ“ Detection pipeline: Successfully applied"),
        Err(e) => println!("   âœ— Detection pipeline: Error - {}", e),
    }

    // 3. Self-supervised Learning Pipeline (aggressive)
    println!("\n3. ðŸ”„ Self-Supervised Learning Pipeline:");
    let ssl_pipeline = Compose::new(vec![
        Box::new(RandomResizedCrop::new((224, 224)).with_scale((0.2, 1.0))),
        Box::new(RandomHorizontalFlip::new(0.5)),
        Box::new(
            ColorJitter::new()
                .brightness(0.8)
                .contrast(0.8)
                .saturation(0.8)
                .hue(0.2),
        ),
        Box::new(RandomErasing::new(0.5)),
        Box::new(Normalize::new(
            vec![0.485, 0.456, 0.406],
            vec![0.229, 0.224, 0.225],
        )),
    ]);

    match ssl_pipeline.forward(&input_tensor) {
        Ok(_) => println!("   âœ“ Self-supervised pipeline: Successfully applied"),
        Err(e) => println!("   âœ— Self-supervised pipeline: Error - {}", e),
    }

    // 4. Fine-tuning Pipeline (conservative)
    println!("\n4. ðŸŽ¯ Fine-tuning Pipeline:");
    let finetune_pipeline = Compose::new(vec![
        Box::new(Resize::new((256, 256))),
        Box::new(RandomCrop::new((224, 224))),
        Box::new(RandomHorizontalFlip::new(0.5)),
        Box::new(ColorJitter::new().brightness(0.1).contrast(0.1)),
        Box::new(Normalize::new(
            vec![0.485, 0.456, 0.406],
            vec![0.229, 0.224, 0.225],
        )),
    ]);

    match finetune_pipeline.forward(&input_tensor) {
        Ok(_) => println!("   âœ“ Fine-tuning pipeline: Successfully applied"),
        Err(e) => println!("   âœ— Fine-tuning pipeline: Error - {}", e),
    }

    println!("\nðŸ’¡ Custom Pipeline Design Principles:");
    println!("   â€¢ Classification: Aggressive augmentation for generalization");
    println!("   â€¢ Object Detection: Preserve spatial relationships");
    println!("   â€¢ Self-Supervised: Very aggressive to learn robust features");
    println!("   â€¢ Fine-tuning: Conservative to preserve pre-trained features");
    println!("   â€¢ Always validate on your specific dataset and task\n");

    Ok(())
}

/// Demonstrate performance considerations and optimizations
fn demonstrate_performance_considerations(
    _config: &AugmentationConfig,
) -> Result<(), Box<dyn Error>> {
    println!("âš¡ Performance Considerations Demo");
    println!("==================================\n");

    println!("ðŸš€ Optimization Strategies:\n");

    println!("1. ðŸ”„ Transform Ordering:");
    println!("   âœ“ Good: Crop â†’ Flip â†’ Color â†’ Normalize");
    println!("   âœ— Bad: Resize â†’ Crop â†’ Resize (redundant operations)");
    println!("   â€¢ Apply spatial transforms before color transforms");
    println!("   â€¢ Keep expensive operations (resize) to minimum");

    println!("\n2. ðŸ’¾ Memory Efficiency:");
    println!("   â€¢ Use in-place operations where possible");
    println!("   â€¢ Avoid creating unnecessary tensor copies");
    println!("   â€¢ Consider tensor slicing over full copies for crops");

    println!("\n3. ðŸ”¢ Batch Processing:");
    println!("   â€¢ Apply transforms to entire batches when possible");
    println!("   â€¢ Use vectorized operations for normalization");
    println!("   â€¢ Leverage GPU acceleration for compute-intensive transforms");

    println!("\n4. ðŸŽ² Randomization Strategy:");
    println!("   â€¢ Use seeded random generators for reproducibility");
    println!("   â€¢ Pre-compute random parameters for entire epochs");
    println!("   â€¢ Balance randomness with performance requirements");

    println!("\n5. ðŸ“Š Monitoring and Profiling:");
    println!("   â€¢ Profile transform pipelines to identify bottlenecks");
    println!("   â€¢ Monitor GPU/CPU utilization during data loading");
    println!("   â€¢ Use async data loading to overlap computation");

    println!("\nðŸ’¡ Performance Best Practices:");
    println!("   â€¢ Profile your specific pipeline on target hardware");
    println!("   â€¢ Use appropriate tensor backends (CPU vs GPU)");
    println!("   â€¢ Consider caching transformed data for small datasets");
    println!("   â€¢ Implement custom transforms for domain-specific needs");
    println!("   â€¢ Balance augmentation strength with training speed\n");

    Ok(())
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_augmentation_pipeline() {
        let config = AugmentationConfig {
            image_size: (64, 64),
            crop_size: (32, 32),
            batch_size: 2,
            num_examples: 4,
        };

        // Test that basic pipeline runs without errors
        assert!(demonstrate_basic_transforms(&config).is_ok());
        assert!(demonstrate_training_augmentations(&config).is_ok());
        assert!(demonstrate_test_augmentations(&config).is_ok());
    }

    #[test]
    fn test_transform_composition() {
        let input = randn(&[3, 64, 64]);

        let pipeline = Compose::new(vec![
            Box::new(Resize::new((32, 32))),
            Box::new(RandomHorizontalFlip::new(0.5)),
            Box::new(Normalize::new(vec![0.5, 0.5, 0.5], vec![0.5, 0.5, 0.5])),
        ]);

        let result = pipeline.forward(&input);
        assert!(result.is_ok());

        let output = result.unwrap();
        assert_eq!(output.shape(), &[3, 32, 32]);
    }

    #[test]
    fn test_individual_transforms() {
        let input = randn(&[3, 64, 64]);

        // Test individual transforms
        assert!(Resize::new((32, 32)).forward(&input).is_ok());
        assert!(RandomHorizontalFlip::new(0.5).forward(&input).is_ok());
        assert!(RandomVerticalFlip::new(0.5).forward(&input).is_ok());
        assert!(ColorJitter::new().brightness(0.2).forward(&input).is_ok());
        assert!(RandomErasing::new(0.1).forward(&input).is_ok());
    }
}
